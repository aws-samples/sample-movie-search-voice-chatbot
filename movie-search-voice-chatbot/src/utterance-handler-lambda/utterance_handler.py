"""
AWS Lambda handler module for processing user utterances and generating responses using Amazon Bedrock.

This module handles incoming user messages through a WebSocket connection, processes them using
Amazon Bedrock's streaming response capabilities, and sends back chunked responses to the client.

Key components:
- Processes user utterances and maintains conversation history in DynamoDB
- Handles streaming responses from Amazon Bedrock model
- Manages WebSocket connections for real-time communication
- Supports special commands like 'CLEAR' to reset conversation history
- Handles XML-formatted responses with support for images and descriptions

Functions:
    process_utterance: Processes a single user utterance and generates response
    lambda_handler: AWS Lambda entry point that handles incoming WebSocket messages
    process_response_stream: Processes streaming responses from Amazon Bedrock model
"""

import json
import logging
from typing import Tuple
from aws_bedrock import invoke_model_with_response_stream
from aws_dynamodb import dynamodb_update_item_data, get_item_data
from aws_websocket import websocket_send_message
from helper_prompt import generate_prompt, check_history_for_relevancy
from helper_record import remove_empty_tag, is_full_record, \
    is_full_unclosed_record, fix_unclosed_record, separate_record, \
    append_description_to_record, append_image_to_record, \
    is_full_answer, separate_answer

logger = logging.getLogger()
logger.setLevel(logging.INFO)


def process_utterance(connection_id: str, utterance: str) -> None:
    """
    Process a user utterance and generate a response.

    Args:
        connection_id: WebSocket connection ID for the client
        utterance: User's input message

    Returns:
        None
    """
    data = get_item_data(connection_id)
    history = data.get('history', [])
    if not data:
        # @todo: error handling
        return None
    if utterance.strip().upper() == 'CLEAR':
        history = []
        websocket_send_message(
            connection_id=connection_id,
            message={
                'action': 'DISPLAY_RESPONSE',
                'value': 'Session history cleared',
                'type': 'TEXT'
            }
        )
    else:
        websocket_send_message(
            connection_id=connection_id,
            message={
                'action': 'WAIT',
                'value': 'BUILDING_RESPONSE',
                'type': 'WAIT'
            })
        _, history = process_response_stream(
            question=utterance,
            history=history,
            connection_id=connection_id,
            chunking=True
        )
    data['history'] = history
    dynamodb_update_item_data(
        connection_id=connection_id,
        data=data
    )
    return None


def lambda_handler(event, _) -> dict:
    """
    AWS Lambda handler function that processes incoming WebSocket messages.

    Args:
        event: AWS Lambda event object
        _: AWS Lambda context object (unused)

    Returns:
        dict: Response object with status code
    """
    logging.info(event)

    for record in event['Records']:
        if 'body' not in record:
            continue
        body = json.loads(record['body'])
        if 'connectionId' not in body:
            continue
        if 'utterance' in body:
            process_utterance(
                connection_id=body['connectionId'],
                utterance=body['utterance']
            )

    return {
        'statusCode': 200,
        'body': json.dumps('Hello from Utterance Handler Lambda!')
    }


def process_response_stream(
    question: str,
    history: list,
    connection_id: str,
    chunking: bool = True
) -> Tuple[str, dict]:
    """
    Process streaming responses from Amazon Bedrock model.

    Handles the streaming response, chunks it appropriately, and sends
    formatted messages back to the client through WebSocket connection.
    Processes XML-formatted responses and handles special cases like images
    and descriptions.

    Args:
        question: User's question/utterance to be processed
        history: List containing conversation history between user and assistant
        connection_id: WebSocket connection ID for sending responses back to client
        chunking: Whether to send response in chunks (default: True)

    Returns:
        Tuple[str, dict]: A tuple containing:
            - str: The complete answer generated by the model
            - dict: Updated conversation history with the new Q&A pair

    Flow:
        1. Invokes Bedrock model with the question and relevant history
        2. Processes streaming response chunks from model
        3. Handles different response formats (answers, records, unclosed records)
        4. Appends images and descriptions where needed
        5. Sends formatted chunks back to client via WebSocket
        6. Updates conversation history with new exchange

    Example:
        answer, history = process_response_stream(
            "What is AWS Lambda?",
            previous_history,
            "connection-123",
            chunking=True
        )
    """
    logging.info('Question: %s', question)
    answer = ''
    answer_chunk = ''

    streaming_response = invoke_model_with_response_stream(
        prompt=generate_prompt(
            question,
            check_history_for_relevancy(history)
        )
    )
    stream = streaming_response['stream']
    if stream:
        for chunk in stream:
            if 'contentBlockDelta' in chunk and 'delta' in chunk['contentBlockDelta']:
                answer_chunk += chunk['contentBlockDelta']['delta']['text']
                if is_full_answer(answer_chunk):
                    answer_chunk, remainder = separate_answer(answer_chunk)
                    answer += answer_chunk
                    if chunking:
                        websocket_send_message(
                            connection_id=connection_id,
                            message={
                                'action': 'DISPLAY_RESPONSE',
                                'value': remove_empty_tag(answer_chunk),
                                'type': 'TEXT'
                            }
                        )
                        logging.info('is_balanced_tag: %s',
                                     remove_empty_tag(answer_chunk))
                        answer_chunk = remainder
                elif is_full_record(answer_chunk):
                    answer_chunk, remainder = separate_record(answer_chunk)
                    answer += answer_chunk
                    answer_chunk = append_image_to_record(answer_chunk)
                    answer_chunk = append_description_to_record(
                        answer_chunk)
                    if chunking:
                        websocket_send_message(
                            connection_id=connection_id,
                            message={
                                'action': 'DISPLAY_RESPONSE',
                                'value': remove_empty_tag(answer_chunk),
                                'type': 'TEXT'
                            }
                        )
                        logging.info('is_balanced_tag: %s',
                                     remove_empty_tag(answer_chunk))
                        answer_chunk = remainder
                elif is_full_unclosed_record(answer_chunk):
                    answer_chunk = fix_unclosed_record(answer_chunk)
                    answer_chunk, remainder = separate_record(answer_chunk)
                    answer += answer_chunk
                    answer_chunk = append_image_to_record(answer_chunk)
                    answer_chunk = append_description_to_record(
                        answer_chunk)
                    if chunking:
                        websocket_send_message(
                            connection_id=connection_id,
                            message={
                                'action': 'DISPLAY_RESPONSE',
                                'value': remove_empty_tag(answer_chunk),
                                'type': 'TEXT'
                            }
                        )
                        logging.info('is_full_unclosed_record: %s',
                                     remove_empty_tag(answer_chunk))
                        answer_chunk = remainder

    if not stream or answer_chunk:
        answer += answer_chunk
        if not chunking:
            websocket_send_message(
                connection_id=connection_id,
                message={
                    'action': 'DISPLAY_RESPONSE',
                    'value': remove_empty_tag(answer),
                    'type': 'TEXT'
                }
            )
        else:
            answer_chunk = fix_unclosed_record(answer_chunk, is_last=True)
            answer_chunk, remainder = separate_record(answer_chunk)
            answer_chunk = append_image_to_record(answer_chunk)
            answer_chunk = append_description_to_record(answer_chunk)
            websocket_send_message(
                connection_id=connection_id,
                message={
                    'action': 'DISPLAY_RESPONSE',
                    'value': remove_empty_tag(answer_chunk),
                    'type': 'TEXT'
                }
            )
            websocket_send_message(
                connection_id=connection_id,
                message={
                    'action': 'DISPLAY_RESPONSE',
                    'value': remove_empty_tag(remainder),
                    'type': 'TEXT'
                }
            )
    logging.info('Answer: %s', answer)
    history.append({'User': question, 'Assistant': answer})

    return answer, history
